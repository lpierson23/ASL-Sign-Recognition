1) Methods already applied for data pre-processing and feature extraction (2 points).
For feature extraction, I utilized the MediaPipe Hands resource https://google.github.io/mediapipe/solutions/hands. 
This process takes in an image and classifies the handiness by flipping the image across the y-axis.
It then converts the image to RGB to further process. The image dimensions are noted to help find finer placement.
This solution uses mp_hands to detect different points on the hand including the wrist, tips and digits of each finger.
The details of this process are not given in the code.
A graph of the found points is then plotted with the coordinates of the point on the original image.

2) A short justification why you decided to use these algorithms (5 points). For instance, if you used Canny edge detection and Hough transform to detect lines, say why you believe this feature extraction is good for your project.
This algorithm will be very useful for my overall project in detecting ASL symbols from an image. From here, I can use the finger tip and other feature coordinates to develop a pattern
for each ASL symbol. For example, for the ASL symbol "b", all fingers except for the thumb are vertical. With the coordinates, I can confirm that the 4 points tracked on each finger have roughly the same y-coordinate. 
Additionally, the thumb will cross into the palm section of the hand. 

3) A few illustrations demonstrating how your methods processed training data, for instance segmentation results (3 points).
The results of the feature extraction can be seen in the file titled "CV_Part3_FeatureDetection.ipynb".
